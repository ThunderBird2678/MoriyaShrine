Image Processing

The image processing software component of this project has two components: a) face detection and b) detection of a laser pointer. The face detection component is based on the work of Darrell et al. (1998), who outlined a relatively simple face detection algorithm. I have adjusted this algorithm to adapt to the constraints of this project. I also implement a rudimentary form of machine learning so as to improve the face detection algorithm.

The foundation of the image processing being performed is the Image class, defined in Image.h and implemented in Main.cpp. The members and functions of this class are described as follows:

Members

int width, height, depth: The dimensions of the image. Depth is the number of color channels - usually 3 for red, green, and blue in that order, or 1 for grayscale images.

std::vector< std::vector< std::vector<int> > > mat: 3-dimensional vector containing the numerical values of the image. Each element is an integer between 0 and 255 inclusive. I use vectors rather than arrays due to ease of use.

std::vector< std::vector<bool> > valid: 2-dimensional vector that acts as a filter for the image, of size widthxheight. Based on various operations, each pixel can be set to a boolean value based on this vector.

Functions

Image(): Default constructor. 

Image(std::vector< std::vector< std::vector<int> > > img): Initializes mat to the parameter img. Also initializes valid to all true by default.

Image(std::vector< std::vector< std::vector<int> > > img, std::vector< std::vector<bool> > val): Initializes mat from the parameter img, and valid from the parameter val.

~Image(): Default destructor.

void colorFilter(int r, int g, int b, double tolerance): If the color of a pixel is not sufficiently close (defined by the tolerance parameter) to the value defined by (r,g,b), its filter is set to false. The metric for closeness is defined logarithmically, based on the method outlined by Darrell et al. (1998). This is used to find colors in the image similar to skin tone, for face detection.

void erode(int r): Erosion is an image morphological operation. For each pixel, if not all pixels within an area of rxr are true, that pixel is set to false. This is used to eliminate noise for face detection. 

void dilate(int r): Dilation is an image morphological operation. For every true pixel, set all pixels within an area of rxr to true. This is used to eliminate noise for face detection. 

std::vector<int> largestConnComp(Image& img): Finds the bounding box for the largest connected component of true pixels. Returns a vector in the form [smallest x value, smallest y value, width, height]. A connected component is one in which every true value is connected to at least one other true value. First, this function finds the size of the largest connected component and keeps track of one pixel in that component. Then, the bounds on that connected component are found. Both of these steps are accomplished by the flood-fill algorithm. Finally, all the data within those bounds is written to the img parameter, passed by reference. This is used to find the areas in an image where a face or laser pointer is most likely to be.

void subtractColor(int r, int g, int b): Subtracts an RGB value from all pixels. This is used to produce an image of the facial area.

std::vector<int> averageColor(std::vector<int> bounds, bool val): Average color of image within some bounds. Returns vector in format [average R, average G, average B]. If parameter val is true, the average color is taken across all pixels where the filter is also true; otherwise, the average is only across pixels where the filter is false. This is useful in the case of finding the background color behind a face or laser pointer, as we do not want to include the actual color of the face or laser pointer. This is used to write an average color value to the RGB LED.

void flatten(): Converts to grayscale by averaging R, G, B values. This is used to produce an image of the facial area.

void threshhold(int thresh): Threshholds a grayscale image. All pixels with a value less than thresh have their filters set to false. This is used to produce an image of the facial area, and to detect bright spots (which could be a laser pointer).

void scaleDown(int w, int h): Scales an image down to size wxh. Uses a basic averaging algorithm. This is used to produce an image of the facial area, to compare to a standard image.

int hammingDist(Image img): Computes sum of absolute differences between each pixel in two images. This is used to determine if an area in the image contains a face.

std::vector<int> detectFace(Image& standard, int r, int g, int b, int& loss, std::vector<int>& params, const double IMG_LEARNING_RATE, std::ofstream* logfile, std::string time): Overall function which detects faces. More explanation below:

Face Detection Algorithm

First, the image is filtered based on similarity to skin color. Then, an opening morphological operation is performed (this consists of erosion followed by dilation). The purpose of this is to eliminate noise, such as very small connected components or irregular edges. The largest connected component is then found. A face, if one exists in the image, is likely to be located here. The image is then cropped to only where this connected component is located. The average face color is subtracted from the image, and it is threshholded and converted to grayscale. This produces an image of the face. It is then scaled down to 16x16, to be compared to a standard facial image, contained in the file std.txt. If the hamming distance between the two images is sufficiently small, the face is considered valid. 

Laser Detection Algorithm

This algorithm is original and considerably simpler than the face detection algorithm. The image is converted to grayscale and then threshholded. Typically, as our webcam produces rather dark images, the laser will be the only object sufficiently bright. However, if other bright objects are in the image, some checks are implemented to see if the detected area is really a laser. If the area is small enough and the most common color is red (we are using a red laser), it is considered a laser. Otherwise, we repeat this process with a different area, until a laser is found or all areas are processed.

Other Functions

string getCurrentTime(): Defined in Main.cpp but not part of the Image class. This function returns the timestamp as a string. It is used for logging purposes.
